{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# I94 - IMMIGRATION AND TEMPERATURES\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "The Immigration and Temperature project is a ETL that gets the information from the different files provided by Udacity, clean them and stores them in a Data Warehouse for future investigation in the correlation of temperature and immigration. It is intenteded to researchers, airline companies and people curious aobut immigration.\n",
    "\n",
    "The project is divided in two main parts, first an exploration of the provided data and second the creation of the ETL.\n",
    "\n",
    "For the first point, the first step will be an **exploration of the data**. Each table will be loaded using Spark, the number of rows will be counted and the schema will be studied and tranformed into a Data Dictionary. Second step it will be testing and cleaning the data. By finding duplicate records, measuring the number of NULL rows or droping columns without interest, it will be possible to design the cleaning transformation. Finnaly, with all that exploration of the data, we will be able to define the Data Model the data must have at the end.\n",
    "\n",
    "The second part if the project is **the ETL creation**. Here the data model created in the previous steps will be sumarized in a script where it also loads it to a Data Warehouse. For this, the data will be first written as parquet files in a S3 bucket and copied from the to a Redshift cluster. The script must also create the database, dropping old tables and make a quality check to prove that everything has runned well.\n",
    "\n",
    "In the final model, using Redshift query system, the data will be easily crossable in order to find correlations between two supposidly indepent facts, immigration and temperature. Using the table time and the table demographics as common point, it should be possible to get a model where both facts are compared side by side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import os\n",
    "import configparser\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import functions\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Load Configuration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('config.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Spark Session Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = \"/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/jvm/java-8-openjdk-amd64/bin\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1: Scope the Project and Gather Data\n",
    "\n",
    "### Scope \n",
    "\n",
    "The scope of this project is to create a database with the follwing data: Immigration data provided by the i94 Arrival and Departure form, historic temperature data from Berkeley Earth data page, US demographics information for all cities in the US bigger than 65.000 persons, provided by US Census Bureau's 2015 American Community Survey and an Airport IATA code list provided by www.ourairports.com.\n",
    "\n",
    "This data must be studied to understand the transformation process needed before loading it in a data base for the analytical use of the researchers. \n",
    "\n",
    "The tools that are going to be use is Jupyter Notebook for the testing, Python as the main code language and Apache Spark as the dataframe engine for the large dataset we are going to explore. Finally, AWS tools Redshift and S3 will be used for storage purposes.\n",
    "\n",
    "### Describe and Gather Data \n",
    "\n",
    "After the exploration of each file, a data dictionay with the description of each field is included.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### I94 Immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495641e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495645e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495639e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "2  5748519.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "3  5748520.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "4  5748521.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "\n",
       "  i94addr  depdate   ...     entdepu  matflag  biryear   dtaddto gender  \\\n",
       "0      CA  20582.0   ...        None        M   1976.0  10292016      F   \n",
       "1      NV  20591.0   ...        None        M   1984.0  10292016      F   \n",
       "2      WA  20582.0   ...        None        M   1987.0  10292016      M   \n",
       "3      WA  20588.0   ...        None        M   1987.0  10292016      F   \n",
       "4      WA  20588.0   ...        None        M   1988.0  10292016      M   \n",
       "\n",
       "  insnum airline        admnum  fltno visatype  \n",
       "0   None      QF  9.495387e+10  00011       B1  \n",
       "1   None      VA  9.495562e+10  00007       B1  \n",
       "2   None      DL  9.495641e+10  00040       B1  \n",
       "3   None      DL  9.495645e+10  00040       B1  \n",
       "4   None      DL  9.495639e+10  00040       B1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94data_df = spark.read.load('./sas_data')\n",
    "i94data_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94data_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94data_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Data dictionary: I94 Immigration data**\n",
    "\n",
    "| Column | Description   |\n",
    "|--------|---------------|\n",
    "| CICID | Id |\n",
    "| I94YR | 4 digit year |\n",
    "| I94MON | Numeric month |\n",
    "| I94CIT & I94RES | Code for immigrant country of birth and residence |\n",
    "| I94PORT | Code for immigrant port of arrival |\n",
    "| ARRDATE | Arrival Date in the USA. |\n",
    "| I94MODE | Mode of transport (1 = Air, 2 = Sea, 3 = Land, 9 = Not reported) |\n",
    "| I94ADDR | Arrival USA state |\n",
    "| DEPDATE | Departure Date from the USA |\n",
    "| I94BIR | Age of Respondent in Years |\n",
    "| I94VISA | Visa codes collapsed into three categories (1 = Business, 2 = Pleasure, 3 = Student)|\n",
    "| COUNT | Used for summary statistics |\n",
    "| DTADFILE | Character Date Field - Date added to I-94 Files |\n",
    "| VISAPOST | Department of State where where Visa was issued |\n",
    "| OCCUP | Occupation that will be performed in U.S. |\n",
    "| ENTDEPA | Arrival Flag - admitted or paroled into the U.S. |\n",
    "| ENTDEPD | Departure Flag - Departed, lost I-94 or is deceased |\n",
    "| ENTDEPU | Update Flag - Either apprehended, overstayed, adjusted to perm residence |\n",
    "| MATFLAG | Match flag - Match of arrival and departure records |\n",
    "| BIRYEAR | 4 digit year of birth |\n",
    "| DTADDTO | Date to which admitted to U.S. (allowed to stay until) |\n",
    "| GENDER | Non-immigrant sex |\n",
    "| INSNUM | INS number |\n",
    "| AIRLINE | Airline used to arrive in U.S. |\n",
    "| ADMNUM | Admission Number |\n",
    "| FLTNO | Flight number of Airline used to arrive in U.S. |\n",
    "| VISATYPE | Class of admission legally admitting the non-immigrant to temporarily stay in U.S. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1820-01-01</td>\n",
       "      <td>2.1010000000000004</td>\n",
       "      <td>3.217</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1820-02-01</td>\n",
       "      <td>6.926</td>\n",
       "      <td>2.853</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1820-03-01</td>\n",
       "      <td>10.767</td>\n",
       "      <td>2.395</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1820-04-01</td>\n",
       "      <td>17.988999999999994</td>\n",
       "      <td>2.202</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1820-05-01</td>\n",
       "      <td>21.809</td>\n",
       "      <td>2.036</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature AverageTemperatureUncertainty     City  \\\n",
       "0  1820-01-01  2.1010000000000004                         3.217  Abilene   \n",
       "1  1820-02-01               6.926                         2.853  Abilene   \n",
       "2  1820-03-01              10.767                         2.395  Abilene   \n",
       "3  1820-04-01  17.988999999999994                         2.202  Abilene   \n",
       "4  1820-05-01              21.809                         2.036  Abilene   \n",
       "\n",
       "         Country Latitude Longitude  \n",
       "0  United States   32.95N   100.53W  \n",
       "1  United States   32.95N   100.53W  \n",
       "2  United States   32.95N   100.53W  \n",
       "3  United States   32.95N   100.53W  \n",
       "4  United States   32.95N   100.53W  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = spark.read.option(\"header\", True).csv('GlobalLandTemperaturesByCity.csv')\n",
    "temp_df.where(temp_df.Country == 'United States').limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8599212"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Data Dictionary: Temperature data**\n",
    "\n",
    "| Column | Description |\n",
    "|--------|---------------|\n",
    "| dt | Date of the measurement |\n",
    "| AverageTemperature | Average temperature in the location on the day |\n",
    "| AverageTemperatureUncertainty | Uncertainty of the measurement |\n",
    "| City | City where the measurement was done |\n",
    "| Country | Country where the measurement was done |\n",
    "| Latitude & Longitude | Coordintates of the city |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### US demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.6</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State Median Age Male Population  \\\n",
       "0     Silver Spring       Maryland       33.8           40601   \n",
       "1            Quincy  Massachusetts       41.0           44129   \n",
       "2            Hoover        Alabama       38.5           38040   \n",
       "3  Rancho Cucamonga     California       34.5           88127   \n",
       "4            Newark     New Jersey       34.6          138040   \n",
       "\n",
       "  Female Population Total Population Number of Veterans Foreign-born  \\\n",
       "0             41862            82463               1562        30908   \n",
       "1             49500            93629               4147        32935   \n",
       "2             46799            84839               4819         8229   \n",
       "3             87105           175232               5821        33878   \n",
       "4            143873           281913               5829        86253   \n",
       "\n",
       "  Average Household Size State Code                       Race  Count  \n",
       "0                    2.6         MD         Hispanic or Latino  25924  \n",
       "1                   2.39         MA                      White  58723  \n",
       "2                   2.58         AL                      Asian   4759  \n",
       "3                   3.18         CA  Black or African-American  24437  \n",
       "4                   2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_df = spark.read.options(header = True, delimiter=';').csv('us-cities-demographics.csv')\n",
    "demo_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+------+\n",
      "|  City|     State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race| Count|\n",
      "+------+----------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+------+\n",
      "|Newark|New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               White| 76402|\n",
      "|Newark|New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|Black or African-...|144961|\n",
      "|Newark|New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               Asian|  7349|\n",
      "|Newark|New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|American Indian a...|  2268|\n",
      "|Newark|New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|  Hispanic or Latino|100432|\n",
      "+------+----------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_df.filter(demo_df.City == \"Newark\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Data Dictionary: US demographics**\n",
    "\n",
    "| Column | Description |\n",
    "|--------|---------------|\n",
    "| City | Name of the city |\n",
    "| State | US state of the city |\n",
    "| Median Age | Median age of the registered population |\n",
    "| Male population | Registered male population |\n",
    "| Female population | Registered female population |\n",
    "| Total population | Total registered population |\n",
    "| Number of Veterans | Total registered veteran population |\n",
    "| Foreign-born | Total number of registered population born in a different country |\n",
    "| Average Household Size | Average number of people living in the same household |\n",
    "| State Code | US state code of the city |\n",
    "| Race & Count |  Count of registered population per race |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Airport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>None</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>None</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>None</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>None</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport           11   \n",
       "1  00AA  small_airport                Aero B Ranch Airport         3435   \n",
       "2  00AK  small_airport                        Lowell Field          450   \n",
       "3  00AL  small_airport                        Epps Airpark          820   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport          237   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0        NA          US      US-PA      Bensalem      00A      None   \n",
       "1        NA          US      US-KS         Leoti     00AA      None   \n",
       "2        NA          US      US-AK  Anchor Point     00AK      None   \n",
       "3        NA          US      US-AL       Harvest     00AL      None   \n",
       "4        NA          US      US-AR       Newport     None      None   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4       None                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airp_df = spark.read.options(header = True).csv('airport-codes_csv.csv')\n",
    "airp_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55075"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airp_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|          type|count|\n",
      "+--------------+-----+\n",
      "| large_airport|  627|\n",
      "|   balloonport|   24|\n",
      "| seaplane_base| 1016|\n",
      "|      heliport|11287|\n",
      "|        closed| 3606|\n",
      "|medium_airport| 4550|\n",
      "| small_airport|33965|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airp_df.groupby(\"type\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4797"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airp_df.select(\"gps_code\", \"local_code\").filter(airp_df.gps_code != airp_df.local_code).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airp_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Data Dictionary: Airport data**\n",
    "\n",
    "| Column | Description |\n",
    "|--------|---------------|\n",
    "| Ident | Identification code |\n",
    "| Type | Type of airport |\n",
    "| Name | Name of the airport |\n",
    "| Elevation_ft | Elevation over sea level in feet |\n",
    "| Continent | Continent of location |\n",
    "| Iso_country | ISO 3166-1 Alapha-2 code of the country | \n",
    "| Iso_region | ISO 3166-2 Alapha-2 code of the region | \n",
    "| Municipality | Municipality where the port is situated |\n",
    "| Gps_code | *UNKNOW* |\n",
    "| Iata_code | International Air Transport Association airport code |\n",
    "| Local_code | *UNKNOW* |\n",
    "| Coordinates | Longitude and latitude of the airport |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 2: Explore and Assess the Data\n",
    "### Explore the Data \n",
    "The first thing we are going to do is find which columns have a low percentage of not null fields, in order to drop the columns, the Integrity check. Then, we will find the number of duplicate rows to erase them, the Duplicate check. And finally, we will set which data is useless to delete it, the Useless check.\n",
    "\n",
    "### Cleaning Steps\n",
    "Right after detecting the quality problems explained above, we will clean the data.\n",
    "\n",
    "Both steps will be done at once.\n",
    "\n",
    "#### - First check: Integrity\n",
    "\n",
    "Drop columns with an integrity (% of rows not null) below 80%.\n",
    "\n",
    "1. I94 Immigration data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Values</th>\n",
       "      <th>% integrity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>entdepu</td>\n",
       "      <td>392</td>\n",
       "      <td>0.012660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>occup</td>\n",
       "      <td>8126</td>\n",
       "      <td>0.262441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>insnum</td>\n",
       "      <td>113708</td>\n",
       "      <td>3.672368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>visapost</td>\n",
       "      <td>1215063</td>\n",
       "      <td>39.242254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gender</td>\n",
       "      <td>2682044</td>\n",
       "      <td>86.620571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i94addr</td>\n",
       "      <td>2943721</td>\n",
       "      <td>95.071816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>depdate</td>\n",
       "      <td>2953856</td>\n",
       "      <td>95.399141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>matflag</td>\n",
       "      <td>2957884</td>\n",
       "      <td>95.529231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>entdepd</td>\n",
       "      <td>2957884</td>\n",
       "      <td>95.529231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>airline</td>\n",
       "      <td>3012686</td>\n",
       "      <td>97.299143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>fltno</td>\n",
       "      <td>3076764</td>\n",
       "      <td>99.368636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>i94bir</td>\n",
       "      <td>3095511</td>\n",
       "      <td>99.974098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>biryear</td>\n",
       "      <td>3095511</td>\n",
       "      <td>99.974098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dtaddto</td>\n",
       "      <td>3095836</td>\n",
       "      <td>99.984595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i94mode</td>\n",
       "      <td>3096074</td>\n",
       "      <td>99.992281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>entdepa</td>\n",
       "      <td>3096075</td>\n",
       "      <td>99.992313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dtadfile</td>\n",
       "      <td>3096312</td>\n",
       "      <td>99.999968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>admnum</td>\n",
       "      <td>3096313</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cicid</td>\n",
       "      <td>3096313</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>i94visa</td>\n",
       "      <td>3096313</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arrdate</td>\n",
       "      <td>3096313</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i94port</td>\n",
       "      <td>3096313</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i94res</td>\n",
       "      <td>3096313</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i94cit</td>\n",
       "      <td>3096313</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i94mon</td>\n",
       "      <td>3096313</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i94yr</td>\n",
       "      <td>3096313</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>count</td>\n",
       "      <td>3096313</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>visatype</td>\n",
       "      <td>3096313</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Column   Values  % integrity\n",
       "18   entdepu      392     0.012660\n",
       "15     occup     8126     0.262441\n",
       "23    insnum   113708     3.672368\n",
       "14  visapost  1215063    39.242254\n",
       "22    gender  2682044    86.620571\n",
       "8    i94addr  2943721    95.071816\n",
       "9    depdate  2953856    95.399141\n",
       "19   matflag  2957884    95.529231\n",
       "17   entdepd  2957884    95.529231\n",
       "24   airline  3012686    97.299143\n",
       "26     fltno  3076764    99.368636\n",
       "10    i94bir  3095511    99.974098\n",
       "20   biryear  3095511    99.974098\n",
       "21   dtaddto  3095836    99.984595\n",
       "7    i94mode  3096074    99.992281\n",
       "16   entdepa  3096075    99.992313\n",
       "13  dtadfile  3096312    99.999968\n",
       "25    admnum  3096313   100.000000\n",
       "0      cicid  3096313   100.000000\n",
       "11   i94visa  3096313   100.000000\n",
       "6    arrdate  3096313   100.000000\n",
       "5    i94port  3096313   100.000000\n",
       "4     i94res  3096313   100.000000\n",
       "3     i94cit  3096313   100.000000\n",
       "2     i94mon  3096313   100.000000\n",
       "1      i94yr  3096313   100.000000\n",
       "12     count  3096313   100.000000\n",
       "27  visatype  3096313   100.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions.integrity(i94data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add here the columns that you want to delete\n",
    "del_cols = ['entdepu', 'occup', 'insnum', 'visapost']\n",
    "old_i94data_df = i94data_df\n",
    "i94data_df = i94data_df.drop(*del_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "2. Temperature data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Values</th>\n",
       "      <th>% integrity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AverageTemperature</td>\n",
       "      <td>8235082</td>\n",
       "      <td>95.765542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AverageTemperatureUncertainty</td>\n",
       "      <td>8235082</td>\n",
       "      <td>95.765542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt</td>\n",
       "      <td>8599212</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>City</td>\n",
       "      <td>8599212</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Country</td>\n",
       "      <td>8599212</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>8599212</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>8599212</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Column   Values  % integrity\n",
       "1             AverageTemperature  8235082    95.765542\n",
       "2  AverageTemperatureUncertainty  8235082    95.765542\n",
       "0                             dt  8599212   100.000000\n",
       "3                           City  8599212   100.000000\n",
       "4                        Country  8599212   100.000000\n",
       "5                       Latitude  8599212   100.000000\n",
       "6                      Longitude  8599212   100.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions.integrity(temp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "There are no columns under 80% of integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "3. US Demographics data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Values</th>\n",
       "      <th>% integrity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Average Household Size</td>\n",
       "      <td>2875</td>\n",
       "      <td>99.446558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Number of Veterans</td>\n",
       "      <td>2878</td>\n",
       "      <td>99.550329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Foreign-born</td>\n",
       "      <td>2878</td>\n",
       "      <td>99.550329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male Population</td>\n",
       "      <td>2888</td>\n",
       "      <td>99.896230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female Population</td>\n",
       "      <td>2888</td>\n",
       "      <td>99.896230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City</td>\n",
       "      <td>2891</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>State</td>\n",
       "      <td>2891</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Median Age</td>\n",
       "      <td>2891</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Total Population</td>\n",
       "      <td>2891</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>State Code</td>\n",
       "      <td>2891</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Race</td>\n",
       "      <td>2891</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Count</td>\n",
       "      <td>2891</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Column  Values  % integrity\n",
       "8   Average Household Size    2875    99.446558\n",
       "6       Number of Veterans    2878    99.550329\n",
       "7             Foreign-born    2878    99.550329\n",
       "3          Male Population    2888    99.896230\n",
       "4        Female Population    2888    99.896230\n",
       "0                     City    2891   100.000000\n",
       "1                    State    2891   100.000000\n",
       "2               Median Age    2891   100.000000\n",
       "5         Total Population    2891   100.000000\n",
       "9               State Code    2891   100.000000\n",
       "10                    Race    2891   100.000000\n",
       "11                   Count    2891   100.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions.integrity(demo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "There are no columns under 80% of integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "4. Airport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Values</th>\n",
       "      <th>% integrity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>iata_code</td>\n",
       "      <td>9189</td>\n",
       "      <td>16.684521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>local_code</td>\n",
       "      <td>28686</td>\n",
       "      <td>52.085338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gps_code</td>\n",
       "      <td>41030</td>\n",
       "      <td>74.498411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>elevation_ft</td>\n",
       "      <td>48069</td>\n",
       "      <td>87.279165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>municipality</td>\n",
       "      <td>49399</td>\n",
       "      <td>89.694054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ident</td>\n",
       "      <td>55075</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>type</td>\n",
       "      <td>55075</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>name</td>\n",
       "      <td>55075</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>continent</td>\n",
       "      <td>55075</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iso_country</td>\n",
       "      <td>55075</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iso_region</td>\n",
       "      <td>55075</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>coordinates</td>\n",
       "      <td>55075</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column  Values  % integrity\n",
       "9      iata_code    9189    16.684521\n",
       "10    local_code   28686    52.085338\n",
       "8       gps_code   41030    74.498411\n",
       "3   elevation_ft   48069    87.279165\n",
       "7   municipality   49399    89.694054\n",
       "0          ident   55075   100.000000\n",
       "1           type   55075   100.000000\n",
       "2           name   55075   100.000000\n",
       "4      continent   55075   100.000000\n",
       "5    iso_country   55075   100.000000\n",
       "6     iso_region   55075   100.000000\n",
       "11   coordinates   55075   100.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions.integrity(airp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Iata_code is only for airports with type \"large_airport\". It shouldn't be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "del_cols = ['local_code', 'gps_code']\n",
    "old_airp_df = airp_df\n",
    "airp_df = airp_df.drop(*del_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### - Second check: Duplicates\n",
    "Dropping the rows duplicated according to the unique columns.\n",
    "\n",
    "\n",
    "1. I94 Immigration data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "col = (['cicid'])\n",
    "i94data_df = functions.d_duplicates(i94data_df, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "2. Airport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "col = (['ident'])\n",
    "airp_df = functions.d_duplicates(airp_df, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "No duplicate rows in any table.\n",
    "\n",
    "#### - Third check: Useless data\n",
    "According to the explored data, we have found that Temp_df has a lot of records with value 'None' that can be deleted. Also, as the demographics and airport info is only related to the US, we can drop the records from other countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_df = temp_df.drop().where(temp_df.AverageTemperature == 'None')\n",
    "temp_df = temp_df.filter(temp_df.AverageTemperature != 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "The Data Model is going to be a snowflake schema that joins the for important pieces of information: Immigration, Airports, Cities and Temperatures. The reason behind this schema is to have a well structured model, where we have dimension talbes related to dimension tables (Demographics to Airports), and make easier to the final user the extraction of the requested data. In the other hand, this schema is more resource consuming than just a data lake. \n",
    "\n",
    "In that way, the finnal user will be able to create queries to extract the desired information using the Time table and the Demographics table as group by criteria. In order to link demographics and immigration, the recommended fields are joining Immigration and Airports on Port = Iata_code and then Airports to Demographics on Municipality = City.\n",
    "\n",
    "**Fact Table** \n",
    "\n",
    "- Immigation_table\n",
    "\n",
    "| Column | TYPE | Other |\n",
    "|--------|----------|----|\n",
    "| Id | INT | PRIMARY |\n",
    "| Arrival_date | INT | KEY of Time Table |\n",
    "| Departure_date | INT | KEY of Time Table |\n",
    "| Birth_country | TEXT ||\n",
    "| Residence_country | TEXT ||\n",
    "| Port | TEXT | KEY of Airport Table |\n",
    "| Age | INT ||\n",
    "| Birth year | INT ||\n",
    "| Visa | TEXT ||\n",
    "| Gender | CHAR ||\n",
    "| Mode | TEXT ||\n",
    "| State | TEXT ||\n",
    "| Type | TEXT ||\n",
    "\n",
    "- Temperature_table\n",
    "\n",
    "| Column | TYPE | Other |\n",
    "|--------|----------|----|\n",
    "| Id | INT | PRIMARY |\n",
    "| Country | TEXT |  |\n",
    "| City | TEXT | KEY of Demographics Table |\n",
    "| Date | INT | KEY of Time Table |\n",
    "| AverageTemp | FLOAT | |\n",
    "| Uncertanty | FLOAT | |\n",
    "\n",
    "\n",
    "**Dimension Tables**\n",
    "\n",
    "- Airport_table\n",
    "\n",
    "| Column | TYPE | Other |\n",
    "|--------|----------|----|\n",
    "| Id | TEXT | PRIMARY |\n",
    "| Type | TEXT | |\n",
    "| Name | TEXT | |\n",
    "| Country | TEXT |  |\n",
    "| Region | TEXT | KEY of Demographics Table |\n",
    "| Municipality | TEXT | KEY of Demographics Table |\n",
    "| Elevation | INT | |\n",
    "| Iata_code | TEXT | |\n",
    "\n",
    "- Demographics_table\n",
    "\n",
    "| Column | TYPE | Other |\n",
    "|--------|----------|----|\n",
    "| Id | INT | Primary |\n",
    "| City | TEXT ||\n",
    "| State | TEXT ||\n",
    "| Median Age | FLOAT ||\n",
    "| Male population | INT ||\n",
    "| Female population | INT ||\n",
    "| Total population | INT ||\n",
    "| Number veterans | INT ||\n",
    "| Foreign born | INT ||\n",
    "| Average household | FLOAT ||\n",
    "| State code | TEXT ||\n",
    "| Race | TEXT ||\n",
    "| Count | INT ||\n",
    "\n",
    "- Time_table\n",
    "\n",
    "| Column | TYPE | Other |\n",
    "|--------|----------|----|\n",
    "| Time | DATE | Primary |\n",
    "| Year | INT ||\n",
    "| Month | INT ||\n",
    "| Day Of Week | INT ||\n",
    "| Day of Month | INT ||\n",
    "| Day of Year | INT ||\n",
    "\n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "1. Create Spark dataframes\n",
    "\n",
    "2. Substitute simple codes with text\n",
    "    - visatype\n",
    "    - birth_country\n",
    "    - residence_country\n",
    "    - port\n",
    "    - addr\n",
    "    \n",
    "3. Delete non-large airports\n",
    "\n",
    "4. Delete duplicates\n",
    "\n",
    "5. Select columns and cast them into the right type\n",
    "\n",
    "6. Export data to S3\n",
    "\n",
    "7. Create database tables:\n",
    "    - immigration_table\n",
    "    - temperature_table\n",
    "    - airport_table\n",
    "    - demographics_table\n",
    "    - time_table\n",
    "    \n",
    "\n",
    "8. Insert the data into Redshift tables\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session created\n",
      "i94data_df created, 3096313 rows.\n",
      "temp_df created, 8599212 rows.\n",
      "demo_df created, 2891 rows.\n",
      "airp_df created , 55075 rows.\n",
      "Number of duplicated rows: 0\n",
      "Number of duplicated rows: 0\n",
      "Time table created\n"
     ]
    }
   ],
   "source": [
    "# Step 1 Pyspark: Extract data and performe transformation\n",
    "import functions\n",
    "spark = functions.spark_init()\n",
    "immi_df, temp_df, demo_df, airp_df = functions.create_dataframe(spark)\n",
    "immi_df, temp_df, demo_df, airp_df = functions.clean_dataframe(spark, immi_df, temp_df, demo_df, airp_df)\n",
    "immi_df, temp_df, demo_df, airp_df = functions.cast_dataframe(spark, immi_df, temp_df, demo_df, airp_df)\n",
    "time_df = functions.create_time(spark, immi_df, temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upload to S3\n",
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- dt: date (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- Uncertainty: double (nullable = true)\n",
      "\n",
      "Temperature data uploaded, 49.013402223587036 seconds\n",
      "root\n",
      " |-- cicid: long (nullable = true)\n",
      " |-- arrdates: date (nullable = true)\n",
      " |-- depdates: date (nullable = true)\n",
      " |-- BirthCountry: string (nullable = true)\n",
      " |-- ResidenceCountry: string (nullable = true)\n",
      " |-- port: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- biryear: integer (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- Mode: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Type: string (nullable = true)\n",
      "\n",
      "Immigration data uploaded, 158.14731645584106 seconds\n",
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- median_age: double (nullable = true)\n",
      " |-- male_population: integer (nullable = true)\n",
      " |-- female_population: integer (nullable = true)\n",
      " |-- total_population: integer (nullable = true)\n",
      " |-- number_of_veterans: integer (nullable = true)\n",
      " |-- foreign_born: integer (nullable = true)\n",
      " |-- average_household_size: double (nullable = true)\n",
      " |-- State_Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      "\n",
      "Demographics data uploaded, 7.832876682281494 seconds\n",
      "root\n",
      " |-- time: date (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- dayofweek: integer (nullable = true)\n",
      " |-- dayofmonth: integer (nullable = true)\n",
      " |-- dayofyear: integer (nullable = true)\n",
      " |-- weekofyear: integer (nullable = true)\n",
      "\n",
      "Time data uploaded, 251.54802131652832 seconds\n",
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation: integer (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      "\n",
      "Airport data uploaded, 15.377377986907959 seconds\n",
      "Upload to s3 completed\n"
     ]
    }
   ],
   "source": [
    "# Step 2 S3: Export data to S3.\n",
    "#CAREFUL: This step can take up to 2 hours. To load just a sample, change the commented lines in functions.py -> upload_s3\n",
    "output_data = 's3a://acr-udacity-capstone-bucket-2/'\n",
    "n = functions.upload_s3(output_data, spark, immi_df, temp_df, demo_df, airp_df, time_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping old tables\n",
      "Old tables dropped\n",
      "Creating new tables\n",
      "New tables created\n",
      "======= LOADING TABLE =======\n",
      "=== DONE IN: 0.56 sec\n",
      "\n",
      "======= LOADING TABLE =======\n",
      "=== DONE IN: 0.56 sec\n",
      "\n",
      "======= LOADING TABLE =======\n",
      "=== DONE IN: 0.48 sec\n",
      "\n",
      "======= LOADING TABLE =======\n",
      "=== DONE IN: 0.50 sec\n",
      "\n",
      "======= LOADING TABLE =======\n",
      "=== DONE IN: 0.61 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3 Redshift: Create database and import the data from S3 to Redshift\n",
    "import functions\n",
    "functions.create_database()\n",
    "functions.insert_redshift()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immigration\n",
      "Perfect integrity\n",
      "Perfect integrity\n",
      "Perfect integrity\n",
      "Temperature\n",
      "Perfect integrity\n",
      "Perfect integrity\n",
      "Perfect integrity\n",
      "Demographics\n",
      "Perfect integrity\n",
      "Perfect integrity\n",
      "Airport\n",
      "Perfect integrity\n",
      "Perfect integrity\n",
      "Perfect integrity\n"
     ]
    }
   ],
   "source": [
    "# Step 4 Quality: Check if all the columns have been imported to Redshift.\n",
    "import functions\n",
    "functions.quality_database(n)\n",
    "functions.integrity_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file.\n",
    "\n",
    "- Immigation\n",
    "\n",
    "| Column | Description | Data type |\n",
    "|--------|----------|---------|\n",
    "| Id | Unique identifier | INT |\n",
    "| Arrival_date | Date when the passenger arrived | DATE |\n",
    "| Departure_date | Date when the passenger should leave | DATE |\n",
    "| Birth_country | Country of birth | TEXT |\n",
    "| Residence_country | Country of residence | TEXT |\n",
    "| Port | Airport where the i94 was registered | TEXT |\n",
    "| Age | Age of the passenger | INT |\n",
    "| Birth year | Year of birth of the passenger | INT |\n",
    "| Visa | Category of visa | TEXT |\n",
    "| Gender | Gender | CHAR |\n",
    "| Mode | Air, land or water | TEXT |\n",
    "| State | State where the passenger arrived | TEXT |\n",
    "| Type | Type of visa | TEXT |\n",
    "\n",
    "- Temperature\n",
    "\n",
    "| Column | Description | Data type |\n",
    "|--------|----------|------|\n",
    "| Id | Unique identifier | INT |\n",
    "| Country | Country where it was measured  | TEXT |\n",
    "| City | City where it was measured | TEXT |\n",
    "| Date | Month of the measurement | DATE |\n",
    "| AverageTemp | Average temperature in Celsius | FLOAT |\n",
    "| Uncertanty | Uncertanty of the measurement | FLOAT |\n",
    "\n",
    "- Airport\n",
    "\n",
    "| Column | Description | Data type |\n",
    "|--------|----------|------|\n",
    "| Id | Unique identifier | TEXT |\n",
    "| Type | Type of airport | TEXT |\n",
    "| Name | Name of the airport | TEXT |\n",
    "| Country | Country where it belongs | TEXT |\n",
    "| Region | Region/State where it belongs | TEXT |\n",
    "| Municipality | Municipality where it belongs | TEXT |\n",
    "| Elevation | Elevation in feet of the airport | INT |\n",
    "| iata_code | International code for the airport | TEXT |\n",
    "\n",
    "- Demographics\n",
    "\n",
    "| Column | Description | Data type |\n",
    "|--------|----------|------|\n",
    "| Id | Unique identifier | INT |\n",
    "| City | City name | TEXT |\n",
    "| State | State where the city is located | TEXT |\n",
    "| Median Age | Meadian age of the residents of the city | FLOAT |\n",
    "| Male population | Amount of male residents | INT |\n",
    "| Female population | Amount of female residents | INT |\n",
    "| Total population | Amount of residents | INT |\n",
    "| Number veterans | Total amount of army veterans | INT |\n",
    "| Foreign born | Amount of residents born abroad | INT |\n",
    "| Average household | Average number of persons living in a house | FLOAT |\n",
    "| State code | Code of the state | TEXT |\n",
    "| Race | Race | TEXT |\n",
    "| Count | Amount of people for the given race | INT |\n",
    "\n",
    "- Time_table\n",
    "\n",
    "| Column | Description | Data type |\n",
    "|--------|----------|-------|\n",
    "| Time | Dates from arrdate, depdate (immigration table) and date (temperature table) | DATE |\n",
    "| Year | Year of the date | INT |\n",
    "| Month | Month of the date | INT |\n",
    "| Day Of Week | Monday = 0, Sunday = 6 | INT |\n",
    "| Day of Month | Day of month | INT |\n",
    "| Day of Year | Day of year | INT |\n",
    "\n",
    "\n",
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 1. Tools justification\n",
    "\n",
    "- Python: The language selected for this project is Python, as its flexibility and its integration with other big data tools like Spark or Redshift makes it the perfect code language.\n",
    "- Spark: Due to the quantity of rows, Spark has been used as dataframe engine. Its distributed computing proceses the files quicker than just the local machine.\n",
    "- Redshift: The data warehouse service from AWS is perfect to store a database accessible to the users remotely and with the computional capacity to execute the requested queries.\n",
    "- S3: Amazon Simple Storage Service let us store cheaply the information as parquet files, from where it can be loaded to Redshift quicker than directly from the local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2. Import schedule\n",
    "- The data provided by i94 has a increasing nature as it would grow each day with new registers, while the temperature information could be added daily. This would suggest a daily, weekly or monthly update depending on the use of the final users. The problem would be the automatition of the update of the data, as there is no API or webhook from where to call the information, it should be done manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 3. Other problems\n",
    "- In case the data would grown 100x, the resources dedicated to Spark and Redshift should be increased. In that way the time taken to run the ETL could be keep it stable. Partition the data according to important columns, like year, country, etc would be useful, but Redshift doesn't work properly with it, so it would require more development to solve the issues. Also, in case not all the needs to be available all the time, S3 could be used as a data lake, triggering a workflow when you need to load an especific partition.\n",
    "- To update the data daily at 7am, an API from where extract the data should be found. That being done, execution the ETL at 7Am can be done with a cron job or using Apache Airflow. This solution on the other hand requires extra instance as you requiere a 24/7 server where to execute an Airflow DAG daily.\n",
    "- In case the number of users that need to use the data grows, more resources should be applied in Redshift to compensate the growths in requests. In case the users are from different world areas, replication of the database in other regions could be an idea to be explored, but it would have a important extra cost. Other solution would be redirect the users to a visualization tool like Power BI, Tableau or Zoho Analytics, where they would connect the database and execute the queries in their local machine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
